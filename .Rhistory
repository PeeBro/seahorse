# be.er  <- arrange(be.er, Sample)
write_csv(n.bio.ECAR, paste0(OUTPUT_PATH,"/ECAR-BioEnergetics.csv"))
# add standard errors
# st.err <- melt(log.be$standard.errors, value.name = "SE", variable.name = "variable" )
# be.er  <- left_join(l.bio.ECAR, st.err, by = c("Sample", "variable"))
# be.er <- arrange(be.er, Sample)
write_csv(l.bio.ECAR, paste0(OUTPUT_PATH,"/logECAR-BioEnergetics.csv"))
# norm estimates boxplots
norm.be.ECAR$estimates %>%
ggplot(aes(Interval,mean))+
ggtitle("ECAR Estimates natural scale")+
geom_boxplot( width = 0.6, outlier.size = -1, show.legend = FALSE, fill="pink", alpha = 0.7)+
# geom_line(aes(group = sample_id, Interval,mean), col = "grey", size = .1, show.legend = FALSE)+
geom_jitter( width = 0.2, show.legend = FALSE, size = 0.5 , alpha = 0.7)+
xlab("Intervals")+
ylab("logECAR")+
theme_bw()
# log estimates boxplots
log.be.ECAR$estimates %>%
ggplot(aes(Interval,mean))+
ggtitle("Log ECAR Estimates")+
geom_boxplot(width = 0.6, outlier.size = -1, show.legend = FALSE, fill="pink", alpha = 0.7)+
# geom_line(aes(group = sample_id, Interval,mean), col = "grey", size = .1, show.legend = FALSE)+
geom_jitter(width = 0.2, show.legend = FALSE, size = 0.5 )+
xlab("Intervals")+
ylab("logECAR")+
theme_bw()
view(dm$ECAR)
E <- dm %>% select(ECAR)
view(E)
E <- dm %>% select(ECAR, Measurement, Interval)
view(E)
E <- dm %>% select(ECAR, Measurement, Interval)
E %>%
ggplot(aes(Interval,ECAR))+
ggtitle("ECAR Estimates natural scale")+
geom_boxplot( width = 0.6, outlier.size = -1, show.legend = FALSE, fill="pink", alpha = 0.7)+
# geom_line(aes(group = sample_id, Interval,mean), col = "grey", size = .1, show.legend = FALSE)+
geom_jitter( width = 0.2, show.legend = FALSE, size = 0.5 , alpha = 0.7)+
xlab("Intervals")+
ylab("logECAR")+
theme_bw()
E <- dm %>% select(ECAR, Measurement, Project, Interval)
E_mean <- E %>% group_by(Project, Interval)
View(E_mean)
E_mean <- E %>% group_by(Project, Interval) %>%
mutate(ECAR_mean = mean(ECAR))
View(E_mean)
E <- dm %>% select(ECAR, Measurement, Project, Interval)
E_mean <- E %>% group_by(Project, Interval) %>%
mutate(ECAR_mean = mean(ECAR))
E_mean %>%
ggplot(aes(Interval,ECAR_mean))+
ggtitle("ECAR Estimates natural scale")+
geom_boxplot( width = 0.6, outlier.size = -1, show.legend = FALSE, fill="pink", alpha = 0.7)+
# geom_line(aes(group = sample_id, Interval,mean), col = "grey", size = .1, show.legend = FALSE)+
geom_jitter( width = 0.2, show.legend = FALSE, size = 0.5 , alpha = 0.7)+
xlab("Intervals")+
ylab("logECAR")+
theme_bw()
E %>%
ggplot(aes(Interval,ECAR))+
ggtitle("ECAR Estimates natural scale")+
geom_boxplot( width = 0.6, outlier.size = -1, show.legend = FALSE, fill="pink", alpha = 0.7)+
# geom_line(aes(group = sample_id, Interval,mean), col = "grey", size = .1, show.legend = FALSE)+
geom_jitter( width = 0.2, show.legend = FALSE, size = 0.5 , alpha = 0.7)+
xlab("Intervals")+
ylab("logECAR")+
theme_bw()
?tick
# Set path and load the package "here"
here::i_am("Experiments/OCR+ECAR-Pipeline.Rmd")
if(!("here" %in% installed.packages()[, "Package"])) {
install.packages("here")
}
library(here)       # Used to set the path to the package dir. on the machine
# Check if all packages are installed
source(here("R", "src", "config_file.R"))
# Load libraries
library(tools)
library(reshape2)
library(reshape)
library(tidyverse)
library(readxl)     # Read xlsx file
library(knitr)      # Used for tables
library(kableExtra)
library(shiny)
# Get input folder
input_folder <- params$input_folder
# Create output folder
output_folder <- sprintf("%s_OUTPUT", input_folder)
o_path <- here("Data", "OUTPUT", output_folder)
if(!dir.exists(o_path)){
dir.create(path = o_path)
}
# source the functions used in analysis
source(here("R", "src", "analysis_source_functions_FOUR_INTERVALS.R"))
# INPUT_PATH  <- (here('/Data/INPUT/ConBIS')) # path to the folder of interest
INPUT_PATH  <- (here('Data', "INPUT", input_folder)) # path to the folder of interest
# OUTPUT_PATH <- (here('/Data/OUTPUT/HF'))
OUTPUT_PATH <- (here('Data', "OUTPUT", output_folder))
# Delete old knit files
knit_cache <- here('Experiments', "OCR+ECAR-Pipeline_cache")
knit_files <- here("Data", "OUTPUT", output_folder, "OCR+ECAR-Pipeline_files")
knit_folders <- c(knit_cache, knit_files)
for (folder in knit_folders) {
if (file.exists(folder))
unlink(folder, recursive = T)
}
# Initialize the knitting process
# rmarkdown::render(here('Experiments', "OCR+ECAR-Pipeline-FOUR-INTERVALS.Rmd"), output_dir = OUTPUT_PATH)
# Read The the separate xlsx files from folder, Specify entire path to folder.
data <- read_xlsx_set(INPUT_PATH, ".xlsx")
dm <- data$rates
view(dm)
?read_xlsx
?read.csv
# source the functions used in analysis
source(here("R", "src", "analysis_source_functions_FOUR_INTERVALS.R"))
# Read The the separate xlsx files from folder, Specify entire path to folder.
data <- read_xlsx_set(INPUT_PATH, ".xlsx")
# Read The the separate xlsx files from folder, Specify entire path to folder.
data <- read_xlsx_set(INPUT_PATH, ".xlsx")
read_xlsx()
?read_xlsx
# source the functions used in analysis
source(here("R", "src", "analysis_source_functions_FOUR_INTERVALS.R"))
# Read The the separate xlsx files from folder, Specify entire path to folder.
data <- read_xlsx_set(INPUT_PATH, ".xlsx")
# Read The the separate xlsx files from folder, Specify entire path to folder.
data <- read_xlsx_set(INPUT_PATH, ".xlsx")
# Read The the separate xlsx files from folder, Specify entire path to folder.
data <- read_xlsx_set(INPUT_PATH, ".xlsx")
View(number_intervals)
# source the functions used in analysis
source(here("R", "src", "analysis_source_functions_FOUR_INTERVALS.R"))
# Read The the separate xlsx files from folder, Specify entire path to folder.
data <- read_xlsx_set(INPUT_PATH, ".xlsx")
# source the functions used in analysis
source(here("R", "src", "analysis_source_functions_FOUR_INTERVALS.R"))
# Read The the separate xlsx files from folder, Specify entire path to folder.
data <- read_xlsx_set(INPUT_PATH, ".xlsx")
# Read The the separate xlsx files from folder, Specify entire path to folder.
data <- read_xlsx_set(INPUT_PATH, ".xlsx")
View(number_intervals)
?drop_na
# Read The the separate xlsx files from folder, Specify entire path to folder.
data <- read_xlsx_set(INPUT_PATH, ".xlsx")
class(number_intervals)
# Read The the separate xlsx files from folder, Specify entire path to folder.
source(here("R", "src", "analysis_source_functions_FOUR_INTERVALS.R"))
data <- read_xlsx_set(INPUT_PATH, ".xlsx")
# Read The the separate xlsx files from folder, Specify entire path to folder.
source(here("R", "src", "analysis_source_functions_FOUR_INTERVALS.R"))
data <- read_xlsx_set(INPUT_PATH, ".xlsx")
data <- read_xlsx_set(INPUT_PATH, ".xlsx")
?gsub
data <- read_xlsx_set(INPUT_PATH, ".xlsx")
intervals[1]
sub(".*: ", "", intervals[1])
sub(".*: ", "", intervals)
data <- read_xlsx_set(INPUT_PATH, ".xlsx")
sub(".*: ", "", intervals[1])
sub(".*: ", "", intervals)
# Read The the separate xlsx files from folder, Specify entire path to folder.
source(here("R", "src", "analysis_source_functions_FOUR_INTERVALS.R"))
data <- read_xlsx_set(INPUT_PATH, ".xlsx")
data <- read_xlsx_set(INPUT_PATH, ".xlsx")
# Read The the separate xlsx files from folder, Specify entire path to folder.
source(here("R", "src", "analysis_source_functions_FOUR_INTERVALS.R"))
# Read The the separate xlsx files from folder, Specify entire path to folder.
source(here("R", "src", "analysis_source_functions_FOUR_INTERVALS.R"))
# Read The the separate xlsx files from folder, Specify entire path to folder.
source(here("R", "src", "analysis_source_functions_FOUR_INTERVALS.R"))
data <- read_xlsx_set(INPUT_PATH, ".xlsx")
data <- read_xlsx_set(INPUT_PATH, ".xlsx")
sprintf("A1:A%f",1000)
sprintf("A1:A%1.0f",1000)
# Read The the separate xlsx files from folder, Specify entire path to folder.
source(here("R", "src", "analysis_source_functions_FOUR_INTERVALS.R"))
data <- read_xlsx_set(INPUT_PATH, ".xlsx")
# Read The the separate xlsx files from folder, Specify entire path to folder.
source(here("R", "src", "analysis_source_functions_FOUR_INTERVALS.R"))
data <- read_xlsx_set(INPUT_PATH, ".xlsx")
data <- read_xlsx_set(INPUT_PATH, ".xlsx")
# Read The the separate xlsx files from folder, Specify entire path to folder.
source(here("R", "src", "analysis_source_functions_FOUR_INTERVALS.R"))
data <- read_xlsx_set(INPUT_PATH, ".xlsx")
data <- read_xlsx_set(INPUT_PATH, ".xlsx")
unique(raw$Measurement)
length(unique(raw$Measurement)) > 1
# Read The the separate xlsx files from folder, Specify entire path to folder.
source(here("R", "src", "analysis_source_functions_FOUR_INTERVALS.R"))
data <- read_xlsx_set(INPUT_PATH, ".xlsx")
# Read The the separate xlsx files from folder, Specify entire path to folder.
source(here("R", "src", "analysis_source_functions_FOUR_INTERVALS.R"))
data <- read_xlsx_set(INPUT_PATH, ".xlsx")
raw %>% group_by(Measurement)
raw %>% table(Measurement)
table(raw$Measurement)
max(table(raw$Measurement))
# Read The the separate xlsx files from folder, Specify entire path to folder.
source(here("R", "src", "analysis_source_functions_FOUR_INTERVALS.R"))
# Read The the separate xlsx files from folder, Specify entire path to folder.
source(here("R", "src", "analysis_source_functions_FOUR_INTERVALS.R"))
data <- read_xlsx_set(INPUT_PATH, ".xlsx")
# Read The the separate xlsx files from folder, Specify entire path to folder.
source(here("R", "src", "analysis_source_functions_FOUR_INTERVALS.R"))
data <- read_xlsx_set(INPUT_PATH, ".xlsx")
sprintf("A1:I%1.0f",measurement_length*3+1)
# Read The the separate xlsx files from folder, Specify entire path to folder.
source(here("R", "src", "analysis_source_functions_FOUR_INTERVALS.R"))
data <- read_xlsx_set(INPUT_PATH, ".xlsx")
data <- read_xlsx_set(INPUT_PATH, ".xlsx")
sprintf("A1:I%1.0f",(measurement_length*3+1))
View(raw)
# Read The the separate xlsx files from folder, Specify entire path to folder.
source(here("R", "src", "analysis_source_functions_FOUR_INTERVALS.R"))
# Read The the separate xlsx files from folder, Specify entire path to folder.
source(here("R", "src", "analysis_source_functions_FOUR_INTERVALS.R"))
data <- read_xlsx_set(INPUT_PATH, ".xlsx")
data <- read_xlsx_set(INPUT_PATH, ".xlsx")
data <- read_xlsx_set(INPUT_PATH, ".xlsx")
length_intervals[1]
# Read The the separate xlsx files from folder, Specify entire path to folder.
source(here("R", "src", "analysis_source_functions_FOUR_INTERVALS.R"))
# Read The the separate xlsx files from folder, Specify entire path to folder.
source(here("R", "src", "analysis_source_functions_FOUR_INTERVALS.R"))
data <- read_xlsx_set(INPUT_PATH, ".xlsx")
data <- read_xlsx_set(INPUT_PATH, ".xlsx")
View(raw)
# Read The the separate xlsx files from folder, Specify entire path to folder.
source(here("R", "src", "analysis_source_functions_FOUR_INTERVALS.R"))
data <- read_xlsx_set(INPUT_PATH, ".xlsx")
data <- read_xlsx_set(INPUT_PATH, ".xlsx")
# Read The the separate xlsx files from folder, Specify entire path to folder.
source(here("R", "src", "analysis_source_functions_FOUR_INTERVALS.R"))
data <- read_xlsx_set(INPUT_PATH, ".xlsx")
View(out_Hg)
data <- read_xlsx_set(INPUT_PATH, ".xlsx")
View(out_Hg)
# Read The the separate xlsx files from folder, Specify entire path to folder.
source(here("R", "src", "analysis_source_functions_FOUR_INTERVALS.R"))
data <- read_xlsx_set(INPUT_PATH, ".xlsx")
View(out_Hg)
data <- read_xlsx_set(INPUT_PATH, ".xlsx")
# Read The the separate xlsx files from folder, Specify entire path to folder.
source(here("R", "src", "analysis_source_functions_FOUR_INTERVALS.R"))
data <- read_xlsx_set(INPUT_PATH, ".xlsx")
dm <- data$rates
# Read The the separate xlsx files from folder, Specify entire path to folder.
source(here("R", "src", "analysis_source_functions_FOUR_INTERVALS.R"))
data <- read_xlsx_set(INPUT_PATH, ".xlsx")
dm <- data$rates
View(dm)
data$Hg_list %>%
kable(caption="Wells removed. Out od 140-160 mmHg interval") %>%
kable_styling()
data$OCR_background %>%
kable(caption="Background measurements not included in OCR correction") %>%
kable_styling()
data$ECAR_background %>%
kable(caption="Background measurements not included in ECAR correction") %>%
kable_styling()
data$Zero_measurements %>%
kable(caption="Background measurements not included in ECAR correction") %>%
kable_styling()
data <- read_xlsx_set(INPUT_PATH, ".xlsx")
data <- read_xlsx_set(INPUT_PATH, ".xlsx")
View(out)
data <- read_xlsx_set(INPUT_PATH, ".xlsx")
View(d)
data$Zero_measurements %>%
kable(caption="Empty measurements") %>%
kable_styling()
# perep for OCR interval 5 not used
d_OCR  <- dm
# filter out samples with any of intervals having less than 8 measurements
sumar <- d_OCR %>%
group_by(sample_id, Interval) %>%
summarise(n = n()) %>%
filter(n < 18) # les then 18 so it corespods to at least 6 different wells
# number of intervals has to be 4 or discarted
inter <- d_OCR %>%
group_by(sample_id) %>%
summarise(n_inter = length(unique(Interval))) %>%
filter(n_inter != 4)
d_OCR <- d_OCR %>%
filter(! sample_id %in% unique(sumar$sample_id))
d_OCR <- d_OCR %>%
filter(! sample_id %in% unique(inter$sample_id))
paste0("Samples removed due lack of usable measurements(less than 8  in any interval)")
unique(sumar$sample_id)
paste0("Samples removed because there are no 4 intervals )")
unique(inter$sample_id)
# Identify Outliars
# DT = loaded dataframe
# cut.well = threshold for well outliaer,
# cut.point = threshold for point outliaer
# x = Variable: "LOCR", "OCR
dr_ocr <- idfy_sinleP_outlier(d_OCR, cut.point = 6, x = "LOCR")
# clean enviroment
rm(d_OCR)
# write the data into file
write_csv(dr_ocr, paste0(OUTPUT_PATH,"/Data_removed_OCR.csv"))
# amount of removed outliars
dr_ocr %>%
group_by(sample_id, is.out.p) %>%
summarise(n = n()) %>%
group_by(sample_id) %>%
mutate(size = sum(n),
ptg = n / size *100,
percentage = paste(format(ptg, digits= 1, nsmall=2),"%")) %>%
filter(is.out.p == T) %>%
arrange(desc(ptg)) %>%
select(sample_id, percentage) %>%
kable(caption="Amount of removed outliers across samples") %>%
kable_styling(full_width = F)
for (smpl in unique(dr_ocr$sample_id)) {
d    <- filter(dr_ocr, sample_id == smpl)
ptg  <- nrow(filter(d, is.out.p == T))/nrow(d)*100
plot <- ggplot(d, aes(Time, OCR))+
ggtitle(paste0("ID: ", smpl, " |  Outliers: ", format(ptg, digits = 3), "%"))+
geom_line(aes(group = Well),size = 0.2, color = "grey") +
geom_point(aes(Time, OCR, color = is.out.p))+
guides(color=guide_legend(title="Outlier"))+
xlab("Measurement")+
ylim(0,15)+
ylab("OCR (Normalized)")
print(plot +theme_bw())
}
# Violin plot LOCR
#  for (smpl in unique(dr_ocr$sample_id)) {
#    d    <- filter(dr_ocr, sample_id == smpl)
#    ptg  <- nrow(filter(d, is.out.p == T))/nrow(d)*100
#    plot <- ggplot(d, aes(Time, LOCR))+
#              ggtitle(paste0("ID: ", smpl, "  out: ", format(ptg, digits = 3), "%"))+
#              geom_violin(aes(Interval, LOCR))+
#              geom_point(aes(Interval, LOCR, color = is.out.p))+
#              xlab("Interval")#+
#
#    print(plot +theme_bw())
# }
for (smpl in unique(dr_ocr$sample_id)) {
d    <- filter(dr_ocr, sample_id == smpl)
ptg  <- nrow(filter(d, is.out.p == T))/nrow(d)*100
plot <- ggplot(d, aes(Time, OCR))+
ggtitle(paste0("ID: ", smpl, " |  Outliers: ", format(ptg, digits = 3), "%"))+
geom_line(aes(group = Well),size = 0.2, color = "grey") +
geom_point(aes(Time, OCR, color = is.out.p))+
guides(color=guide_legend(title="Outlier"))+
xlab("Measurement")+
ylim(0,15)+
ylab("OCR (Normalized)")
print(plot +theme_bw())
}
# Violin plot LOCR
#  for (smpl in unique(dr_ocr$sample_id)) {
#    d    <- filter(dr_ocr, sample_id == smpl)
#    ptg  <- nrow(filter(d, is.out.p == T))/nrow(d)*100
#    plot <- ggplot(d, aes(Time, LOCR))+
#              ggtitle(paste0("ID: ", smpl, "  out: ", format(ptg, digits = 3), "%"))+
#              geom_violin(aes(Interval, LOCR))+
#              geom_point(aes(Interval, LOCR, color = is.out.p))+
#              xlab("Interval")#+
#
#    print(plot +theme_bw())
# }
for (smpl in unique(dr_ocr$sample_id)) {
d    <- filter(dr_ocr, sample_id == smpl)
ptg  <- nrow(filter(d, is.out.p == T))/nrow(d)*100
plot <- ggplot(d, aes(Time, OCR))+
ggtitle(paste0("ID: ", smpl, " |  Outliers: ", format(ptg, digits = 3), "%"))+
geom_line(aes(group = Well),size = 0.2, color = "grey") +
geom_point(aes(Time, OCR, color = is.out.p))+
guides(color=guide_legend(title="Outlier"))+
xlab("Measurement")+
ylim(0,15)+
ylab("OCR (Normalized)")
print(plot +theme_bw())
}
# Violin plot LOCR
#  for (smpl in unique(dr_ocr$sample_id)) {
#    d    <- filter(dr_ocr, sample_id == smpl)
#    ptg  <- nrow(filter(d, is.out.p == T))/nrow(d)*100
#    plot <- ggplot(d, aes(Time, LOCR))+
#              ggtitle(paste0("ID: ", smpl, "  out: ", format(ptg, digits = 3), "%"))+
#              geom_violin(aes(Interval, LOCR))+
#              geom_point(aes(Interval, LOCR, color = is.out.p))+
#              xlab("Interval")#+
#
#    print(plot +theme_bw())
# }
print(plot +theme_bw())
norm.be <- compute_bioenergetics_(dr_ocr, "OCR")
log.be  <- compute_bioenergetics_(dr_ocr, "LOCR")
write_csv(norm.be$estimates, paste0(OUTPUT_PATH,"/OCR-Estimated_values.csv"))
write_csv(log.be$estimates, paste0(OUTPUT_PATH,"/LOCR-Estimates_values.csv"))
write_csv(norm.be$bioenergetics, paste0(OUTPUT_PATH,"/OCR-BE-table.csv"))
write_csv(log.be$bioenergetics, paste0(OUTPUT_PATH,"/LOCR-BE-table.csv"))
# Print interval estimates
norm.be$estimates[1:4,] %>%
kable(digits = 3, caption = "Example of estimates file ") %>%
kable_styling(full_width = F)
# norm estimates boxplots
ggplot(norm.be$estimates)+
ggtitle("OCR Estimates natural scale")+
geom_boxplot(aes(Interval,mean), width = 0.6, outlier.size = -1, show.legend = FALSE, fill = "pink")+
geom_jitter(aes(Interval,mean), width = 0.2, show.legend = FALSE, size = 0.5 )+
xlab("Intervals")+
ylab("OCR")+
theme_bw()
# log estimates boxplots
ggplot(log.be$estimates)+
ggtitle("logOCR Estimates")+
geom_boxplot(aes(Interval,mean), width = 0.6, outlier.size = -1, show.legend = FALSE, fill = "pink")+
geom_jitter(aes(Interval,mean), width = 0.2, show.legend = FALSE, size = 0.5 )+
xlab("Intervals")+
ylab("logOCR")+
theme_bw()
# ADD coefficients of variation
# normal scale Bioenergetics
n.bio <- melt(norm.be$bioenergetics)
n.bio %>%
filter(variable != "Other") %>%
ggplot(aes(variable, value, fill = variable ))+
ggtitle("Difference based natural scale Bio-Energetics OCR")+
geom_boxplot(width = 0.5, outlier.size = -1, alpha = 0.7)+
geom_jitter(width = 0.1, show.legend = FALSE, size = 0.5 )+
xlab("Bio-Energetics")+
ylab(" ")+
theme_bw()
# log scale Bioenergetics
l.bio   <- melt(log.be$bioenergetics )
l.bio %>%
filter(variable != "Other") %>%
ggplot(aes(variable, value, fill = variable))+
ggtitle("Ratio based log scale Bio-Energetics OCR (folds)")+
geom_boxplot( width = 0.5, outlier.size = -1, alpha = 0.7)+
geom_jitter( width = 0.1, show.legend = FALSE, size = 0.5 )+
xlab(" Log Bio-Energetics")+
ylab(" ")+
theme_bw()
# difference based BE
n.bio %>%
mutate(Group = ifelse(grepl("A", Sample), "A", "B")) %>% # change "A" and "B" for any character or string
ggplot(aes(Group, value, fill = variable))+
ggtitle("OCR Normal scale Bio-Energetics biological groups ")+
geom_boxplot(width = 0.5, outlier.size = -1, alpha = 0.7)+
geom_jitter(width = 0.1, show.legend = FALSE, size = 0.5)+
xlab("Bio-Energetics")+
ylab("OCR")+
facet_grid(. ~ variable ) +
theme_bw()
# ratio based BE
l.bio %>%
mutate(Group = ifelse(grepl("A", Sample), "A", "B")) %>% # change "A" and "B" for any character or string
ggplot(aes(Group, value, fill = variable))+
ggtitle("OCR Log scale Bio-Energetics biological groups ")+
geom_boxplot(width = 0.5, outlier.size = -1, alpha = 0.7)+
geom_jitter(width = 0.1, show.legend = FALSE, size = 0.5)+
xlab("Bio-Energetics")+
ylab("OCR")+
facet_grid(. ~ variable ) +
theme_bw()
# Read The the separate xlsx files from folder, Specify entire path to folder.
source(here("R", "src", "analysis_source_functions_FOUR_INTERVALS.R"))
data <- read_xlsx_set(INPUT_PATH, ".xlsx")
dm <- data$rates
View(dm)
data <- read_xlsx_set(INPUT_PATH, ".xlsx")
# Set path and load the package "here"
here::i_am("Experiments/OCR+PER-Pipeline.Rmd")
if(!("here" %in% installed.packages()[, "Package"])) {
install.packages("here")
}
library(here)       # Used to set the path to the package dir. on the machine
# Check if all packages are installed
source(here("R", "src", "config_file.R"))
# Load libraries
library(tools)
library(reshape2)
library(reshape)
library(tidyverse)
library(readxl)     # Read xlsx file
library(knitr)      # Used for tables
library(kableExtra)
library(shiny)
# Get input folder
input_folder <- params$input_folder
# Create output folder
output_folder <- sprintf("%s_OUTPUT", input_folder)
o_path <- here("Data", "OUTPUT", output_folder)
if(!dir.exists(o_path)){
dir.create(path = o_path)
}
# source the functions used in analysis
source(here("R", "src", "analysis_source_functions_FOUR_INTERVALS.R"))
# INPUT_PATH  <- (here('/Data/INPUT/ConBIS')) # path to the folder of interest
INPUT_PATH  <- (here('Data', "INPUT", input_folder)) # path to the folder of interest
# OUTPUT_PATH <- (here('/Data/OUTPUT/HF'))
OUTPUT_PATH <- (here('Data', "OUTPUT", output_folder))
# Delete old knit files
knit_cache <- here('Experiments', "OCR+PER-Pipeline_cache")
knit_files <- here("Data", "OUTPUT", output_folder, "OCR+PER-Pipeline_files")
knit_folders <- c(knit_cache, knit_files)
for (folder in knit_folders) {
if (file.exists(folder))
unlink(folder, recursive = T)
}
# Initialize the knitting process
rmarkdown::render(here('Experiments', "OCR+PER-Pipeline-FOUR-INTERVALS.Rmd"), output_dir = OUTPUT_PATH)
